{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fichier de test de la classe model avant soumission Codalab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path; path.append(\"../ingestion_program\") # Pour l'accès à DataManager\n",
    "from model import model # Modèle avec méthodes\n",
    "from data_manager import DataManager # Gestion du jeu de données\n",
    "from sklearn.model_selection import train_test_split # Découpage du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info file found : /home/tp-home003/mvincen1/L2/S4/malaria/starting_kit/public_data/malaria_public.info\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../public_data'\n",
    "data_name = 'malaria'\n",
    "D = DataManager(data_name, data_dir, replace_missing=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(D.data['X_train'], D.data['Y_train'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codalab():\n",
    "    \"\"\" Le code mystique de Codalab \"\"\"\n",
    "    \n",
    "    # Instance de model\n",
    "    M = model()\n",
    "\n",
    "    # Entrainement du modèle\n",
    "    M.fit(X_train, y_train)\n",
    "\n",
    "    # Labels prédits\n",
    "    y_pred = M.predict(X_test)\n",
    "\n",
    "    # Calcul du score avec y_test les labels réels\n",
    "    score = M.score(y_test, y_pred)\n",
    "\n",
    "    # Affichage du résultat\n",
    "    print(\"score =\", score)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False], 'criterion': ['gini', 'entropy'], 'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260, 270, 280, 290], 'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, None], 'min_samples_split': [2, 3, 4], 'min_samples_leaf': [1, 2, 3, 4], 'random_state': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Optimisation des hyperparamètres à ne lancer qu'une seule fois\n",
    "\n",
    "# Instance de model\n",
    "M = model()\n",
    "# Optimisation plus importante plus n_iter grand\n",
    "M.optimize(X_train, y_train, n_iter=500)\n",
    "# Sauvegarde du modèle\n",
    "M.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests automatiques de l'optimisation\n",
    "\n",
    "# Qualité du score\n",
    "M = model() # Instance\n",
    "M.classfier.fit(X_train, y_train) # Juste pour le test\n",
    "simple_score = M.score(y_test, M.predict(X_test)) # Score sans optimisation\n",
    "M.fit(X_train, y_train) # Entrainement avec optimisation\n",
    "optimization_score = M.score(y_test, M.predict(X_test)) # Score avec optimisation\n",
    "assert(simple_score <= optimization_score) # Le score optimisé doit être supérieur\n",
    "\n",
    "# Concordance des paramètres\n",
    "params = M.get_params() # Paramètres effectifs\n",
    "# Paramètres testés\n",
    "tested_params={'bootstrap':[True,False],\n",
    "               'criterion':[\"gini\", \"entropy\"], \n",
    "               'n_estimators':[i for i in range(10,300,10)], \n",
    "               'max_depth':[i for i in range(1,10)]+[None], \n",
    "               'min_samples_split':[i for i in range(2,5)], \n",
    "               'min_samples_leaf':[i for i in range(1,5)],\n",
    "               'random_state':[i for i in range(1,100)]}\n",
    "\n",
    "for tp in tested_params.keys():\n",
    "    assert(params[tp] in tested_params[tp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codalab()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
