{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fichier de test de la classe model avant soumission Codalab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sys import path; path.append(\"../ingestion_program\") # Pour l'accès à DataManager\n",
    "from model import model # Modèle avec méthodes\n",
    "from data_manager import DataManager # Gestion du jeu de données\n",
    "from sklearn.model_selection import train_test_split # Découpage du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info file found : C:\\Users\\minic\\OneDrive\\Documents\\L2 S4\\Mini Projet\\Malaria\\starting_kit\\public_data\\malaria_public.info\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../public_data'\n",
    "data_name = 'malaria'\n",
    "D = DataManager(data_name, data_dir, replace_missing=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(D.data['X_train'], D.data['Y_train'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codalab():\n",
    "    \"\"\" Le code mystique de Codalab \"\"\"\n",
    "    \n",
    "    # Instance de model\n",
    "    M = model()\n",
    "\n",
    "    # Entrainement du modèle\n",
    "    M.fit(X_train, y_train)\n",
    "\n",
    "    # Labels prédits\n",
    "    y_pred = M.predict(X_test)\n",
    "\n",
    "    # Calcul du score avec y_test les labels réels\n",
    "    score = M.score(y_test, y_pred)\n",
    "\n",
    "    # Affichage du résultat\n",
    "    print(\"score =\", score)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimisation des hyperparamètres à ne lancer qu'une seule fois\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Instance de model\n",
    "M = model()\n",
    "# Optimisation plus importante plus n_iter grand\n",
    "#M.optimize(X_train, y_train, n_iter=500)\n",
    "# Sauvegarde du modèle\n",
    "M.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model reloaded from: ./_model.pickle\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-cad8c10dda92>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Entrainement avec optimisation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0moptimization_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Score avec optimisation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimple_score\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0moptimization_score\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Le score optimisé doit être supérieur\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Concordance des paramètres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Tests automatiques de l'optimisation\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Qualité du score\n",
    "M = model() # Instance\n",
    "M.classifier.fit(X_train, y_train) # Juste pour le test\n",
    "simple_score = M.score(y_test, M.classifier.predict(X_test)) # Score sans optimisation\n",
    "M.fit(X_train, y_train) # Entrainement avec optimisation\n",
    "optimization_score = M.score(y_test, M.predict(X_test)) # Score avec optimisation\n",
    "assert(simple_score <= optimization_score) # Le score optimisé doit être supérieur\n",
    "\n",
    "# Concordance des paramètres\n",
    "params = M.get_params() # Paramètres effectifs\n",
    "# Paramètres testés\n",
    "tested_params={'bootstrap':[True,False],\n",
    "               'criterion':[\"gini\", \"entropy\"], \n",
    "               'n_estimators':[i for i in range(10,300,10)], \n",
    "               'max_depth':[i for i in range(1,10)]+[None], \n",
    "               'min_samples_split':[i for i in range(2,5)], \n",
    "               'min_samples_leaf':[i for i in range(1,5)],\n",
    "               'random_state':[i for i in range(1,100)]}\n",
    "\n",
    "for tp in tested_params.keys():\n",
    "    assert(params[\"classifier__\" + tp] in tested_params[tp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model reloaded from: ./_model.pickle\n",
      "score = 0.941746944644141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.941746944644141"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "codalab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
